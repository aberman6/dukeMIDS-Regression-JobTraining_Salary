---
title: "Team Project 1"
author: "Allison Young and Anna Berman"
date: "10/25/2018"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE, warning=FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd('/Users/annaberman/Desktop/702 Modeling/Assignments/Team Project #1')
library(ggplot2)
library(dplyr)
library(gridExtra) # arranging multiple plots
library(arm)
library(MASS)
library(pROC)
library(knitr)
```

## Data Overview 

During the National Supported Work Demonstration (NSWD) study, researchers assessed whether or not job training for disadvantaged workers had an effect on their wages. Eligible workers were randomly assigned either to receive job training or not to receive job training. We analyze a subset of the data from the NSWD.*

We will use linear and logistic regression modeling to answer the following questions of interest.

* Is there evidence that workers who receive job training tend to earn higher wages than workers who do not receive job training? What is a likely range for the effect of training? Is there any evidence that the effects differ by demographic groups? 

* Is there evidence that workers who receive job training tend to be more likely to have positive (non-zero) wages than workers who do not receive job training? What is a likely range for the effect of training? Is there any evidence that the effects differ by demographic groups? 

A summary of the dataset used in both our linear and logistic regression is summarized below:

```{r data, echo = FALSE, comment = NA}
# Load the data
lalonde <- read.csv('lalondedata.txt') %>%
    mutate(treat = as.factor(treat)) %>%
    mutate(treat = factor(treat, levels = c(0, 1))) %>%
    # mean centering
    mutate(re78c = re78 - mean(re78),
           re75c = re75 - mean(re75),
           re74c = re74 - mean(re74),
           agec = age - mean(age)) %>%
    # Employed in 1978
    mutate(employed78 = ifelse(re78 > 0, 1, 0),
           employed75 = ifelse(re75 > 0, 1, 0),
           employed74 = ifelse(re74 > 0, 1, 0)) %>%
    # educ
    mutate(educ.bin = ifelse(educ < 9, 'MS or less',
                             ifelse(educ < 12, 'Some HS',
                                    ifelse(educ == 12, 'HS', 'More than HS')))) %>%
    mutate(educ.bin = factor(educ.bin, levels = c('HS', 'MS or less', 'Some HS', 'More than HS'))) %>%
    mutate(educ.bin2 = ifelse(educ < 9, 'MS or less', 'Some HS +')) %>%
    mutate(educ.bin2 = factor(educ.bin2, levels = c('Some HS +', 'MS or less'))) %>%
    # age polynomial
    mutate(age2 = agec**2, age3 = agec**3) 


summary(lalonde[, seq(2,20)])
```



# Linear Regression
## Exploratory Data Analysis

For concern of multicolinearity, we cannot include both nodegree and education in our model (nodegree is, in essence, a binned version of education with 0 being over 12 years of education and 1 being less than 12 years of education). We were originally concerned with including both 1974 salary (re74) and 1975 salary (re75), however, the correlation between these two variables is only `r round(cor(lalonde$re74, lalonde$re75),2)` which is low enough to allow both salary variables as predictors in our model. No other variables had high enough correlation to be a multicolinearity concern.

A plot of each predictor in relation to our outcome variable, 1978 salary is below.

```{r exploratory.linear, echo = FALSE, fig.height=5, message = FALSE, warning = FALSE}
# TREAT
e1 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = treat, y = re78)) + 
    ylim(c(0,60000)) + 
    ggtitle('Treatment') +
    ylab('1978 Salary')

# AGE
e2 <- ggplot(lalonde) +
    geom_point(mapping = aes(x = age, y = re78)) + 
    ylim(c(0,61000)) + 
    ggtitle('Age (years)') +
    ylab('1978 Salary')


# EDCU.BIN
e3 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = educ.bin, y = re78)) + 
    ylim(c(0,61000)) + 
    ggtitle('Binned Education') +
    ylab('1978 Salary')


# BLACK
e4 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = as.factor(black), y = re78)) + 
    ylim(c(0,61000)) + 
    ggtitle('Black') +
    ylab('1978 Salary')


# HISPAN
e5 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = as.factor(hispan), y = re78)) + 
    ylim(c(0,61000)) + 
    ggtitle('Hispanic') +
    ylab('1978 Salary')


# MARRIED
e6 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = as.factor(married), y = re78)) + 
    ylim(c(0,61000)) + 
    ggtitle('Married') +
    ylab('1978 Salary')


# RE74
e7 <- ggplot(lalonde) +
    geom_point(mapping = aes(x = re74, y = re78)) + 
    ylim(c(0,61000)) + 
    xlim(c(0,61000)) +
    ggtitle('1974 Salary') +
    ylab('1978 Salary')


# RE75
e8 <- ggplot(lalonde) +
    geom_point(mapping = aes(x = re75, y = re78)) + 
    ylim(c(0,61000)) + 
    xlim(c(0,61000)) + 
    ggtitle('1975 Salary') +
    ylab('1978 Salary')

# NODEGREE
e9 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = as.factor(nodegree), y = re78)) + 
    ylim(c(0,61000))+ 
    ggtitle('No Degree') +
    ylab('1978 Salary')


# Plot all the plots together
grid.arrange(e1, e2, e3, e4, e5, e6, e7, e8, e9,
             top = 'Predictors vs. 1978 Salary')
```

 
## Model Selection

Through a series of modeling fittings, we examined a variety of logistic models to answer the question, 'Is there evidence that workers who receive job training tend to earn higher wages than workers who do not receive job training?'. We evaluated each model based on R-squared value and whether addition variables and interactions resulted in a significant or near-significant nested F test result.
 
We attempted logging our outcome variable (1978 salary (re78)), logging 1974 and 1975 salaries, using nodegree as opposed to education, using education as a continuous variable as well as a binned factor variable. We also looked at potential interaction effects between treatment and education, treatment and black, treatment and Hispanic, and treatment and age (For further details on considered interaction effects ,see appendix). Ultimately, we included a binned version of education separating those with no high school education, some high school education, high school completion, and additional education beyond high school (see exploratory plots for incentive for variable alteration). Additionally, we used mean-centered continuous variables to aid in interpretation.

Before we finalized our model selection, we examined the residuals and influential points. The residuals of this model are normally distributed and have constant variance thus our model fits our assumptions of linear regression (see appendix). The most influential points in our model were determined to be corner cases and did not call for alteration of our final model. (For further details on our model's residuals and influential points, see appendix).

Ultimately, we selected the model summarized below. 

```{r model.linear, echo = FALSE, comment = NA}
final_linear_fit <- lm(re78 ~ treat + agec + educ.bin + black + hispan + married + re74c + re75c, data = lalonde)
summary(final_linear_fit)

coeff <- cbind(summary(final_linear_fit)$coefficients[, c(1,2)],
               confint(final_linear_fit))
coeff <- data.frame(coeff) 
names(coeff) <- c('Estimate', 'Std.Error', '2.5%', '97.5%')
coeff
```

## Interpretation

Our model has an R-squared of `r round(summary(final_linear_fit)$r.squared,2)`. In other words, our model explains `r round(summary(final_linear_fit)$r.squared,2)*100`% of the variance in 1978 salary.

**Intercept**: For non-black, non-Hispanic, un-married individuals of average age, average 1974 and 1975 salaries, with High School only education, who did not receive treatment, we estimate the average salary in 1978 to be \$`r round(coeff['(Intercept)','Estimate'],2)` (95% CI: \$`r round(coeff['(Intercept)','2.5%'],2)`, \$`r round(coeff['(Intercept)','97.5%'],2)`). 

**Treatment**: Holding all else constant, individuals who participated in the treatment are estimated to have an average 1978 salaries increase of \$`r round(coeff['treat','Estimate'],2)` (95% CI: \$`r round(coeff['treat','2.5%'],2)`, \$`r round(coeff['treat','97.5%'],2)`).

**Age**: Holding all else constant, for each 10 years an individual ages on average we estimate his salary to increase by \$`r round(coeff['agec','Estimate']*10,2)` (95% CI: \$`r round(coeff['agec','2.5%']*10,2)`, \$`r round(coeff['agec','97.5%']*10,2)`). Given that this confidence interval includes 0, we are not confident that there is a meaningful effect of age on 1978 salary.

**Education**: Holding all else contant, for an individual with:

* Less than a middle school education: we estimate avergage 1978 salary to be \$`r -round(coeff['educ.binMS or less','Estimate'],2)` less (95% CI: \$`r round(coeff['educ.binMS or less','2.5%'],2)`, \$`r round(coeff['educ.binMS or less','97.5%'],2)`). 

* Some high school education: we estimate avergage 1978 salary to be \$`r round(coeff['educ.binSome HS','Estimate'],2)` more (95% CI: \$`r round(coeff['educ.binSome HS','2.5%'],2)`, \$`r round(coeff['educ.binSome HS','97.5%'],2)`). Given that this confidence interval includes 0, we are not confident that there is a meaningful effect of some high school compared to completion of high school on 1978 salary.

* More than a high school education: we estimate avergage 1978 salary to be \$`r round(coeff['educ.binMore than HS','Estimate'],2)` more (95% CI: \$`r round(coeff['educ.binMore than HS','2.5%'],2)`, \$`r round(coeff['educ.binMore than HS','97.5%'],2)`).

**Married**: Holding all else constant, for married individuals we estimate average 1978 salaries to be \$`r round(coeff['married','Estimate'],2)` more (95% CI: \$`r round(coeff['married','2.5%'],2)`, \$`r round(coeff['married','97.5%'],2)`). Given that this confidence interval includes 0, we are not confident that there is a meaningful effect of being married on 1978 salary.

**Black**: Holding all else constant, for Black individuals we estimate average 1978 salaries to be \$`r -round(coeff['black','Estimate'],2)` less (95% CI: \$`r round(coeff['black','2.5%'],2)`, \$`r round(coeff['black','97.5%'],2)`). Given that this confidence interval includes 0, we are not confident that there is a meaningful effect of being Black on 1978 salary.

**Hispanic**: Holding all else constant, for Hispanic individuals we estimate average 1978 salaries to be \$`r round(coeff['hispan','Estimate'],2)` more (95% CI: \$`r round(coeff['hispan','2.5%'],2)`, \$`r round(coeff['hispan','97.5%'],2)`). Given that this confidence interval includes 0, we are not confident that there is a meaningful effect of hispanic ethnicity on 1978 salary.

**1974 Salary**: Holding all else constant, for each $1,000 an individual made in 1974, on average we estimate his 1978 salary to be \$`r round(coeff['re74c','Estimate']*1000,2)` higher (95% CI: \$`r round(coeff['re74c','2.5%']*1000,2)`, \$`r round(coeff['re74c','97.5%']*1000,2)`). 

**1975 Salary**: Holding all else constant, for each $1,000 an individual made in 1975, on average we estimate his 1978 salary to be \$`r round(coeff['re75c','Estimate']*1000,2)` higher (95% CI: \$`r round(coeff['re75c','2.5%']*1000,2)`, \$`r round(coeff['re75c','97.5%']*1000,2)`). 

## Discussion

Our findings suggest that participation in the examined job training results in increased salaries. Because this is a randomized control trial, we can say this is a casual effect. However the effect size may be small. Specifically, we estimate that individuals who participated in job training to have average 1978 salaries increased by \$`r round(coeff['treat','Estimate'],2)` however this effect could be as small as \$`r round(coeff['treat','2.5%'],2)` or as large as \$`r round(coeff['treat','97.5%'],2)`.

Additionally, our findings suggest that 1978 salary is also mediated by level of education and previous salary. Specifically, education above high school is positively associated with 1978 salary and education level below 9th grade being negatively associated with 1978 salary. In other words, it is unclear whether having a high school diploma differs significantly from having some high school education when it comes to salary in 1978. However, it is clear that having less than a high school education results in a lower salary, and having more than a high school education results in a higher salary.

Simiarly, higher 1974 and 1975 salaries are both indepedently associated with increased 1978 salaries. Interestingly, the relationship betweetn 1974 and 1978 salary appears to be stronger than that between 1975 and 1978 salary. In other words, it appears the 1974 salary of individuals is more representative of earning potential in 1978 compared to 1975, and thus a stronger predictor factor of 1978 salary in our final model.

On the other hand, age, race, ethnicity and marital status may or may not have an effect on salary. This is evident because, when isolated, the cofidence intervals of the model coefficients include zero.


### Limitations

Our model has an R-squared of `r round(summary(final_linear_fit)$r.squared,2)`. In other words, our model explains `r round(summary(final_linear_fit)$r.squared,2)*100`% of the variance 1978 salary. These results suggest that there are additional variables that may be stronger predictors of salary than are included in our dataset. More research is needed to fully understand the relationship between job training programs and salary and the mediating variables in this relationship.

Additionally, our model appears to be less predictive for those with relatively high 1974 or 1975 salaries. This may be due to the lack of observations including high starting salaries. Additional research is needed to fully understand the relationship between salary and job trainings for those high above average salary before job training.


# Logistic Regression

## Exploratory Data Analysis

In terms of mulicollinearity, by the same reasoning as decribed in our linear regression summary, our only restriciton is a mutually exclusive choice between either education or nodegree. 

A plot of each predictor in relation to our outcome variable, nonzero wage in 1978, is below (nonzero wage being defined as salary above 0).

```{r log.explore, echo = FALSE, as.is = TRUE}
# Create table of means
treat <- tapply(lalonde$employed78, lalonde$treat, mean)
educ.bin2 <- tapply(lalonde$employed78, lalonde$educ.bin2, mean) 
black <- tapply(lalonde$employed78, lalonde$black, mean) 
hispan <- tapply(lalonde$employed78, lalonde$hispan, mean) 
married <- tapply(lalonde$employed78, lalonde$married, mean) 
nodegree <- tapply(lalonde$employed78, lalonde$nodegree, mean) 

# Print table
rbind(treat, educ.bin2, black, hispan, married, nodegree) %>%
    round(2) %>%
    kable(caption = 'Average Nonzero Salary \'78 Cases by predictor')
```

```{r,echo = FALSE, fig.height = 4.5, fig.width=5, fig.align='center'}
par(mfrow = c(2,2))
#EDUC
binnedplot(x = lalonde$educ, y = lalonde$employed78,
           xlab = 'Education', ylab = 'Nonzero Salary \'78 Cases',
           ylim = c(0,1),
           main = 'Education')

# AGE
binnedplot(x = lalonde$age, y = lalonde$employed78,
           xlab = 'Age', ylab = 'Nonzero Salary \'78 Cases',
           ylim = c(0,1),
           main = 'Age')


# RE74
binnedplot(x = lalonde$re74, y = lalonde$employed78,
           xlab = 'Re74', ylab = 'Nonzero Salary \'78 Cases',
           ylim = c(.6,1),
           main = '1974 Salary')

# RE75
binnedplot(x = lalonde$re75, y = lalonde$employed78,
           xlab = 'Re75', ylab = 'Nonzero Salary \'78 Cases',
           ylim = c(.6,1),
           main = '1975 Salary')
par(mfrow = c(1,1))
```


## Model Selection

We examined a variety of linear models to answer the question, 'Is there evidence that workers who receive job training tend to be more likely to have positive (non-zero) wages than workers who do not receive job training?'. We evaluated each model based on the area under the curve (AUC) and whether additional variables and interactions resulted in a significant or near-significant change in deviance tests.

We attempted binning education in multiple ways, adding nonzero 1974 and 1975 salary variables. We also examined potential interactions between treatment and previous salaries as well as interactions between treatment and level of education (see appendix for examination of interaction effects). Ultimately we included a binned version of education separating those with at least some high school education or more and those with no high school education (see exploratory plots for incentive for variable alteration). The only interaction that resulted in a significant change in deviance test was the addition of an interaction effect between nonzero 1974 salary and treatement. 

Additionally, we used mean-centered continuous variables to aid in interpretation.

Before we finalized our model selection, we examined the residuals and influential points. The residuals of this model fit our assumptions of logistic regression (see appendix). The most influential points in our model were determined to be corner cases and did not call for alteration of our final model. (For further details on our model's redisuals and influential points, see appendix).

Ultimately, we selected the model summarized below. 

```{r model.log, echo = FALSE, fig.height=3, message= FALSE, fig.width=3, fig.align='center', comment = NA}
# Final fit
final_log_fit <- glm(employed78 ~ treat*employed74 + agec + married + black + hispan + 
                         educ.bin2 + re75c, 
                     data = lalonde, family = binomial)
summary(final_log_fit)

roc <- roc(lalonde$treat, fitted(final_log_fit))
plot(roc)

# Confusion matrix
threshold <- .82
matrix <- round(prop.table(table(lalonde$employed78, 
                                 final_log_fit$fitted > threshold), 1)*100,1)
print('Confusion Matrix')
table(lalonde$employed78,final_log_fit$fitted > threshold)

# Coefficient matrix
coeff <- cbind(exp(summary(final_log_fit)$coefficients[, 1]),
               exp(confint(final_log_fit)))
coeff <- data.frame(coeff) 
names(coeff) <- c('Estimate', '2.5%', '97.5%')
print('Confidence intervals')
coeff
```

## Interpretation

Our model has an AUC of `r round(auc(roc),2)`. Using the suggested threshold of `r threshold`, our model has a sensitivity of `r matrix[2,2]/100` and a specificity of `r (matrix[1,1]/100)`. In other words, our model correctly predicts `r matrix [2,2]`% of nonzero wage earners and `r matrix [1,1]`% of zero wage earners.

**Intercept**: For non-black, non-hispanic, un-married individuals of average age, average 1975 salaries and a zero 1974 salary, with some High School or more education, who did not recieve treatment, we estimate the odds of nonzero salary 1978 to be `r round(coeff['(Intercept)','Estimate'],2)` (95% CI: `r round(coeff['(Intercept)','2.5%'],3)`, `r round(coeff['(Intercept)','97.5%'],2)`). 

**Treatment**: Holding all else constant, for individuals who participated in the treatment we estimate the odds of nonzero salary in 1978 to increase by a factor of `r round(coeff['treat1','Estimate'],2)` (95% CI: `r round(coeff['treat1','2.5%'],2)`, `r round(coeff['treat1','97.5%'],2)`).

**Education**: Holding all else contant, for an individual less than a middle school education we estimate the odds of nonzero salary in 1978 to decrease by a factor of `r round(coeff['educ.bin2MS or less','Estimate'],2)` (95% CI: `r round(coeff['educ.bin2MS or less','2.5%'],2)`, `r round(coeff['educ.bin2MS or less','97.5%'],2)`). 

**Age**: Holding all else constant, for each 10 years an individual ages on average we estimate odds of nonzero salary in 1978 decrease by a factor of `r round(exp(log(coeff['agec','Estimate'])*10),2)` (95% CI: `r round(exp(log(coeff['agec','2.5%'])*10),2)`, `r round(exp(log(coeff['agec','97.5%'])*10),2)`).

```{r, echo = FALSE, fig.height=3}
# AGE
# Create dummy dataset for charting
newval_age <- data.frame(treat = as.factor(0),
                     employed74 = 0,
                     age = seq(min(lalonde$age), max(lalonde$age)),
                     married = 0,
                     black = 0,
                     hispan = 0,
                     educ.bin2 = 'Some HS +',
                     re75c= 0) %>%
    mutate(agec = age - mean(age))

# Predict responses
predict <- predict.glm(final_log_fit, newval_age, interval = 'response', se.fit = TRUE)

# Create confidence interval
t <- 1.96 ## approx 95% CI
upr <- predict$fit + (t * predict$se.fit)
lwr <- predict$fit - (t * predict$se.fit)
fit <- predict$fit

# Append predictions
newval_age <- newval_age %>%
    mutate(fit = exp(fit),
           lwr = exp(lwr),
           upr = exp(upr))

# Print plot
g1 <- ggplot(data = newval_age) + 
    geom_line(mapping = aes(x = age, y = fit) ) + 
    geom_line(mapping = aes(x = age, y = lwr), color = 'grey') +
    geom_line(mapping = aes(x = age, y = upr),  color = 'grey') +
    ylab('Odds of nonzero salary in 1978') + 
    xlab('Age') +
    ggtitle('Age') +
    labs(subtitle = 'Confidence Interval')

# 75 SALARY
# Create dummy dataset for charting
newval_75 <- data.frame(treat = as.factor(0),
                     employed74 = 0,
                     agec = 0,
                     married = 0,
                     black = 0,
                     hispan = 0,
                     educ.bin2 = 'Some HS +',
                     re75 = seq(min(lalonde$re75), max(lalonde$re75))) %>%
    mutate(re75c = re75 - mean(re75))

# Predict responses
predict <- predict.glm(final_log_fit, newval_75, interval = 'response', se.fit = TRUE)

# Create confidence interval
t <- 1.96 ## approx 95% CI
upr <- predict$fit + (t * predict$se.fit)
lwr <- predict$fit - (t * predict$se.fit)
fit <- predict$fit

# Append predictions
newval_75 <- newval_75 %>%
    mutate(fit = exp(fit),
           lwr = exp(lwr),
           upr = exp(upr))

# Print plot
g2 <- ggplot(data = newval_75) + 
    geom_line(mapping = aes(x = re75, y = fit) ) + 
    geom_line(mapping = aes(x = re75, y = lwr), color = 'grey') +
    geom_line(mapping = aes(x = re75, y = upr),  color = 'grey') +
    ylab('Odds of nonzero salary in 1978') + 
    xlab('1975 Salary') +
    ggtitle('1975 Salary') +
    labs(subtitle = 'Confidence Interval')

grid.arrange(g1, g2, nrow = 1,
             top = 'Odds of nonzero salary in 1978')
```

**Married**: Holding all else constant, for married individuals we estimate the odds of nonzero wage in 1978 to increase by a factor of `r round(coeff['married','Estimate'],2)` (95% CI: `r round(coeff['married','2.5%'],2)`, `r round(coeff['married','97.5%'],2)`). Given that this confidence interval includes 1, we are not confident that there is a meaningful effect of being married on odds of nonzero salary in 1978.

**Black**: Holding all else constant, for Black individuals we estimate the odds of nonzero wage in 1978 to decrease by a factor of `r round(coeff['black','Estimate'],2)` (95% CI: `r round(coeff['black','2.5%'],2)`, `r round(coeff['black','97.5%'],2)`).

**Hispanic**: Holding all else constant, for Hispanic individuals we estimate the odds of nonzero wage in 1978 to increase by a factor of `r round(coeff['hispan','Estimate'],2)` (95% CI: `r round(coeff['hispan','2.5%'],2)`, `r round(coeff['hispan','97.5%'],2)`). Given that this confidence interval includes 1, we are not confident that there is a meaningful effect of hispanic ethnicity on odds of nonzero salary in 1978.

**1975 Salary**: Holding all else constant, for each $1,000 an individual made in 1975, on average we estimate the odds of nonzero wage in 1978 to increase by a factor of `r round(exp(log(coeff['re75c','Estimate'])*1000),2)` (95% CI:`r round(exp(log(coeff['re75c','2.5%'])*1000),2)`, `r round(exp(log(coeff['re75c','97.5%'])*1000),2)`). 


**1974 Salary (Zero vs. Nonzero)**:

```{r, echo = FALSE, fig.height=2, warning = FALSE, message = FALSE}
# Rebase our models so we can discuss the impacts of 1974 nonzero salary
# Nonzero 1974
lalonde_1974 <- lalonde %>% 
    mutate(employed74 = factor(employed74, levels = c(1,0)))

log_fit_74 <- glm(employed78 ~ treat*employed74 + agec + age2 + age3 + 
                         married + black + hispan + educ.bin2 + re75c, 
                     data = lalonde_1974, family = binomial)
coeff_74 <- cbind(exp(summary(log_fit_74)$coefficients[, 1]),
               exp(confint(log_fit_74)))
coeff_74 <- data.frame(coeff_74) 
names(coeff_74) <- c('Estimate', '2.5%', '97.5%')
```

* Zero Salary: Holding all else constant, for individuals who participated in the treatment we estimate the odds of nonzero wage in 1978 to increase by a factor of `r round(coeff['treat1','Estimate'],2)` (95% CI: `r round(coeff['treat1','2.5%'],2)`, `r round(coeff['treat1','97.5%'],2)`). 

* Nonzero Salary: Holding all else constant, for individuals who participated in the treatment we estimate the odds of nonzero wage in 1978 to decrease by a factor of `r round(coeff_74['treat1','Estimate'],2)` (95% CI: `r round(coeff_74['treat1','2.5%'],2)`, `r round(coeff_74['treat1','97.5%'],2)`). Given that this confidence interval includes 1, we are not confident that there is a meaningful effect of treatment on nonzero salary in 1978 for those with nonzero salaries in 1974.

```{r, echo = FALSE, fig.height=3}
# Create dummy dataset for charting
newval_74 <- data.frame(treat = as.factor(c(0,0,1,1)),
                     employed74 = c(0,1,0,1),
                     agec = 0,
                     married = 0,
                     black = 0,
                     hispan = 0,
                     educ.bin2 = 'Some HS +',
                     re75c = 0)

# Predict responses
predict <- predict.glm(final_log_fit, newval_74, interval = 'response', se.fit = TRUE)

# Create confidence interval
t <- 1.96 ## approx 95% CI
upr <- predict$fit + (t * predict$se.fit)
lwr <- predict$fit - (t * predict$se.fit)
fit <- predict$fit

# Append predictions
newval_74 <- newval_74 %>%
    mutate(fit = exp(fit),
           lwr = exp(lwr),
           upr = exp(upr))

newval_74 %>%
    mutate(employed74 = ifelse(employed74 == 0, 'Zero 1974 Salary', 'Nonzero 1974 Salary')) %>%
    ggplot() + 
    facet_grid(. ~ employed74) +
    geom_point(mapping = aes(x = treat, y = fit) ) + 
    geom_point(mapping = aes(x = treat, y = lwr), shape = 1) +
    geom_point(mapping = aes(x = treat, y = upr), shape = 1) +
    ylab('Odds of nonzero salary in 1978') + 
    xlab('Treament') +
    ggtitle('Interaction effect of nonzero 1974 salary on treatment') + 
    labs(subtitle = 'Confidence Interval')
    

```

## Discussion

According to our findings, for those with no wages in 1974, participating in the training program has a positive effect on the odds of having a positive wage in 1978, increasing the odds of a nonzero wage in 1978 by an estimated factor of `r round(coeff['treat1','Estimate'],2)`. However, we can not say with certainty whether the impact is the same for those with nonzero wages in 1974. For those with nonzero wages in 1974, our estimates indicate that the job training program may actually have a negative impact, decreasing odds of nonzero wage in 1978 by an estimated factor of `r round(coeff_74['treat1','Estimate'],2)`. There appears to be a negative effect on the odds of nonzero wage for those who were employed in 1974, but we are not able to say with confidence that this effect is negative.  Moreover, we are unable to say an interaction between treatment and nonzero wage in 1974 exists. The confidence intervals overlap, and as such, the true odds ratio may be the same for both groups.

Odds of nonzero wage in 1978 are also influenced by level of education, age, being black. Specifically, level of education not including any high school, increased age, and blackness are all associated with decreased odds of nonzero wage in 1978. In other words, increased age, an elementary or middle-school level education, or being black are all associated with increased odds of zero wages. On the other hand, higher 1975 salary is assocaited with increased odds of nonzero wage in 1978.

Additionally, being Hispanic and being married may or may not be associated with odds of nonzero wage in 1978. When all other factors are held constant, each of these factors has an odds ratio confidence interval that includes 1.0.

## Limitations

There are several limitations to our model that should be taken into consideration when interpreting results. First, while the confidence interval for the odds ratio of nonzero wage in 1978 for an individual in a job training program doesn't include 1.0, it is very close to 1.0. Therefore, while a positive effect is likely, it may not be large.

Second, our resulting model has a low area under the curve (AUC) of `r round(auc(roc),2)`. Therefore, an AUC of `r round(auc(roc),2)` is on the lower end of the possible range of .5-1.0. Specific to our model, there is a sizable difference in the sensitivity (.820) and specificity `(.424) of our model. Meaning, while our model is good at predicting individuals likely to have zero wages in 1978, it is not as good at capturing the breadth of individuals who do truly have nonzero wages in 1978.

# Multi-Model Conclusion

Based on our models, there is good evidence that job training positively influences the odds of nonzero wage and the salaries of individuals who complete the program. However, neither our linear model nor our logistic model provide confidence in large increases in odds of nonzero wage nor salaries, as they both have large confidence intervals.

\pagebreak

# Appendix

*These and other data were originally analyzed by the economist Robert Lalonde (Lalonde, R. J. (1986), Evaluating the econometric evaluations of training programs with experimental data, The American Economic Review, 76, 604 - 620.)

## Interaction Effects

### Linear Model
Below is an exploration of potential interaction effects between treatment and other predictor variables in our dataset. Although some exploratory analysis seemed to indicate an possible interaction effect, no addition of interaction terms meaningfully increased our models performance. Therefore our final model did not include any interaction effects.

```{r, echo = FALSE, fig.heigh = 10}
# AGE
i1 <- ggplot(lalonde) +
    geom_point(mapping = aes(x = age, y = re78)) + 
    ylim(c(0,61000)) + 
    facet_grid(. ~ treat)

# EDUC
i3 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = as.factor(educ), y = re78)) + 
    ylim(c(0,61000)) + 
    facet_grid(. ~ treat)

i4 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = educ.bin, y = re78)) + 
    ylim(c(0,61000)) + 
    facet_grid(. ~ treat)


# RE74
i5 <- ggplot(lalonde) +
    geom_point(mapping = aes(x = re74, y = re78)) + 
    ylim(c(0,61000)) + 
    facet_grid(. ~ educ.bin)

# BLACK
i6 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = as.factor(black), y = re78)) + 
    ylim(c(0,61000)) + 
    facet_grid(. ~ treat)

# HISPAN
i7 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = as.factor(hispan), y = re78)) + 
    ylim(c(0,61000)) + 
    facet_grid(. ~ treat)

# MARRIED
i8 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = as.factor(married), y = re78)) + 
    ylim(c(0,61000)) + 
    facet_grid(. ~ treat)

# NODEGREE
i9 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = as.factor(nodegree), y = re78)) + 
    ylim(c(0,61000)) + 
    facet_grid(. ~ treat)

grid.arrange(i1, i3, i4, i5, i6, i7, i8, i9,
             top = 'Potential Interaction Effects: Linear Model')
```

### Logistic Model

Below is an exploration of potential interaction effects between treatment and other predictor variables in our dataset. The only interaction effect that meaningfully improved prediction for our model was the addition an interaction between a nonzero wage in 1974 and treatment.

```{r, echo = FALSE, fig.height = 3}
par(mfrow = c(1,2))
# Treatment and 74 salary
# No reason for interaction effect
binnedplot(x = lalonde[lalonde$treat == 0, 're74'], y = lalonde[lalonde$treat == 0, 'employed78'],
           xlab = 'Re74', ylab = 'employed78 \'78 Cases',
           ylim = c(.6,1),
           xlim = c(0,20000),
           main = 'No Treatment')
binnedplot(x = lalonde[lalonde$treat == 1, 're74'], y = lalonde[lalonde$treat == 1, 'employed78'],
           xlab = 'Re74', ylab = 'employed78 \'78 Cases',
           ylim = c(.6,1),
           xlim = c(0,20000),
           main = 'Treatment')

# Treatment and 75 salary
# No reason for interaction effect
binnedplot(x = lalonde[lalonde$treat == 0, 're75'], y = lalonde[lalonde$treat == 0, 'employed78'],
           xlab = 'Re75', ylab = 'employed78 \'78 Cases', 
           ylim = c(.6,1),
           xlim = c(0,20000),
           main = 'No Treatment')
binnedplot(x = lalonde[lalonde$treat == 1, 're75'], y = lalonde[lalonde$treat == 1, 'employed78'],
           xlab = 'Re75', ylab = 'employed78 \'78 Cases',
           ylim = c(.6,1),
           xlim = c(0,20000),
           main = 'Treatment')

# Binary 75 employed
# Treatment doesn't have an effect for those who were in employed in 75
# but does have a significant effect if unemployed in 74
tab <- rbind(tapply(lalonde[lalonde$treat == 0, 'employed78'], lalonde[lalonde$treat == 0, 'employed75'], mean),
             tapply(lalonde[lalonde$treat == 1, 'employed78'], lalonde[lalonde$treat == 1, 'employed75'], mean))
rownames(tab) <- c('No Treatment', 'Treatment')
colnames(tab) <- c('Zero wage 75', 'Employed 75')
tab

# Binary 74 employed
# Interaction effect that might wash out when we add 75 interaction
tab <- rbind(tapply(lalonde[lalonde$treat == 0, 'employed78'], lalonde[lalonde$treat == 0, 'employed74'], mean),
             tapply(lalonde[lalonde$treat == 1, 'employed78'], lalonde[lalonde$treat == 1, 'employed74'], mean))
rownames(tab) <- c('No Treatment', 'Treatment')
colnames(tab) <- c('Zero wage 74', 'Employed 74')
tab


# Treatment and educ.bin2
# No reason for interaction effect
# Might help those with lower education
tab <- rbind(tapply(lalonde[lalonde$treat == 0, 'employed78'], lalonde[lalonde$treat == 0, 'educ.bin2'], mean),
             tapply(lalonde[lalonde$treat == 1, 'employed78'], lalonde[lalonde$treat == 1, 'educ.bin2'], mean))
rownames(tab) <- c('No Treatment', 'Treatment')
colnames(tab) <- c('Some HS +', 'MS or less')
tab
```



## Residuals

### Linear Model

```{r, echo = FALSE}
# TREAT
r1 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = treat, y = final_linear_fit$residuals)) + 
    ylab('Residuals')

# AGE
r2 <- ggplot(lalonde) +
    geom_point(mapping = aes(x = age, y = final_linear_fit$residuals)) + 
    ylab('Residuals') 

# EDUC
r3 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = educ.bin, y = final_linear_fit$residuals)) + 
    ylab('Residuals')

# BLACK
r4 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = as.factor(black), y = final_linear_fit$residuals)) + 
    ylab('Residuals') 

# HISPAN
r5 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = as.factor(hispan), y = final_linear_fit$residuals)) + 
    ylab('Residuals')

# MARRIED
r6 <- ggplot(lalonde) +
    geom_boxplot(mapping = aes(x = as.factor(married), y = final_linear_fit$residuals)) + 
    ylab('Residuals')

# RE74
r7 <- ggplot(lalonde) +
    geom_point(mapping = aes(x = re74, y = final_linear_fit$residuals)) + 
    ylab('Residuals')

# RE75
r8 <- ggplot(lalonde) +
    geom_point(mapping = aes(x = re75, y = final_linear_fit$residuals)) + 
    ylab('Residuals') 

grid.arrange(r1, r2, r3, r4, r5, r6, r7, r8,
             top = 'Linear Model Residuals')

```

```{r, fig.height=3, fig.width=3, fig.align='center', echo = FALSE}
qqnorm(final_linear_fit$residuals, ylim = c(-15000,30000))
```



### Logistic Model

```{r, echo = FALSE, comment = NA, fig.height=3, fig.width=3, fig.align='center'}
# Calculate logistical model residuals
rawreds <- lalonde$employed78 - fitted(final_log_fit)

# educ.bin2
print('Education (educ.bin2)')
tapply(rawreds, lalonde$educ.bin2, mean) 

# black
print('Black')
tapply(rawreds, lalonde$black, mean) 

# hispan
print('Hispanic')
tapply(rawreds, lalonde$hispan, mean) 

# married
print('Married')
tapply(rawreds, lalonde$married, mean)

# employed74
print('Nonzero 1974 Salary')
tapply(rawreds, lalonde$employed74, mean) 

# AGE
binnedplot(x = lalonde$age, y = rawreds,
           xlab = 'Age', ylab = 'Residuals')
```


## Influential Points

### Linear Model
Observations with high leverage or cooks distance in our final linear model are below:
```{r influential, echo = FALSE, fig.align='center'}
library(MASS)
# Calcate leveage and cooks distance for each observation
leverage = hatvalues(final_linear_fit)
cooks = cooks.distance(final_linear_fit)

# Append leverage and cooks to our data
leverage <- lalonde %>%
    mutate(leverage, cooks)

# Plot leverage vs. id
l <- ggplot(data = leverage) +
    geom_point(mapping = aes(x = seq(nrow(lalonde)), y = leverage)) +
    labs(subtitle = 'Leverage')
# Plot cooks vs. id
c <- ggplot(data = leverage) +
    geom_point(mapping = aes(x = seq(nrow(lalonde)), y = cooks)) +
    labs(subtitle = 'High Cooks Distance')

grid.arrange(l, c, top = 'Potentially Influential Points')

# Take a look at the potentially influential points
leverage %>%
    filter(leverage > .05 | cooks > .02)
```

The influential points show that our model is not as accurate in its predictions for those who have high salaries in either 1974 or 1975. Because these are not the typical demographic to partake in a job training program, they are not of great interest for this research paper. Therefore we do not alter our model. 

### Logistic Model

Observations with high leverage or cooks distance in our final logistic model are below:
```{r influential2, echo = FALSE, fig.align='left'}
library(MASS)
# Calcate leveage and cooks distance for each observation
leverage = hatvalues(final_log_fit)
cooks = cooks.distance(final_log_fit)

# Append leverage and cooks to our data
leverage <- lalonde %>%
    mutate(leverage, cooks)

# Plot leverage vs. id
l <- ggplot(data = leverage) +
    geom_point(mapping = aes(x = seq(nrow(lalonde)), y = leverage)) +
    labs(subtitle = 'Leverage')
# Plot cooks vs. id
c <- ggplot(data = leverage) +
    geom_point(mapping = aes(x = seq(nrow(lalonde)), y = cooks)) +
    labs(subtitle = 'High Cooks Distance')

grid.arrange(l, c, top = 'Potentially Influential Points')

# Take a look at the potentially influential points
leverage %>%
    filter(leverage > .04 | cooks > .012)
```

We see that many of influential points are those who have nonzero salary in 1974, but who have a zero salary in 1978. These are, in fact, outliers in our observation as they are people who seem to be meaningfully financially worse off in 1978 than in 1974. These cases are potentially influential in our model, but are scientifically relevant cases to include in our observations. Because we cannot justify removing these observations from our dataset, we leave our model unaltered.

Additionally, there are several outliers including relatively high 1978 salaries. Again, although this observation is not the norm, we include this observation in our model as it is an important edge case.

